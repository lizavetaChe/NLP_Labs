{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OaEalOPt7lg"
   },
   "source": [
    "# NLP: Автоматическое построение рефератов текстовых документов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zOsOHFRpZrC",
    "outputId": "2b1facd5-c65d-430e-e7d0-591fb8484361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Downloading datasets-4.2.0-py3-none-any.whl (506 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.3/506.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-4.2.0 pyarrow-21.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers datasets sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hxJmkmZLHEds"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AtT36Aqjuq27"
   },
   "outputs": [],
   "source": [
    "MAX_CHARS = 300\n",
    "MODEL = \"sarahai/ru-sum\"\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^а-яА-ЯёЁ0-9.,!?;:\\-()\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dON8LZbIHN4J"
   },
   "source": [
    "### Загрузка модели и токенизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4350a887573e4899a43bdb41409601a7",
      "a7669d9d0d1f4614903110ef337a8265",
      "c9e8945ef4ae4172956ea076d134386b",
      "8df8c88564fe40e8ae72b88288f95d51",
      "c8264eb10bca446392fcae7a96d75264",
      "651aef63e96f45dd8b7ed3411892316a",
      "d0eeb2d65ad5457bbe3d540bd5407568",
      "3aa21a774e7941389845cb1acbe5640c",
      "051b517c070042a28f0bc576cca58bf5",
      "3a7168d40001416ea1354c0ad684692e",
      "2a03eed912fb40d2aaa79ba3444bf433",
      "1387bb34f3264a41be1ded94c813a43a",
      "faec7092ca1c417a94a3aa5744529309",
      "d4cb8a6d980245f28b4140291da5fc03",
      "2dbdd48c9ca84ac6a5e899029e2551cf",
      "364e28a1f55b4f1faef598b718246135",
      "098acef407c942ccb8e9884325ce04ef",
      "f251d6d9c19a41359fe5e21f6f4b79d6",
      "6ba8ff415c674b86b8c34437648d28f7",
      "ac96baadac764e8bbe70abd95270f270",
      "49c5e3e61ff746d380a30129bae7586c",
      "56be0669706d4dd98a10a78400962571",
      "9009a84d68714d6fa7181f7a717189b5",
      "851b8cdeeb034ae785fe76fc848190a1",
      "2cfa0a89afe946a39fd655fef09e29ed",
      "d88b67008d6e411aa5b5de2049f20eff",
      "82abf3b0d69f4abebc15808dc2303e18",
      "5d08a1fd3b264bf3be7514bd631215d8",
      "ffeab109fc5340f19032166b460ecb2b",
      "e537b7b1790848b3ba9fda3a7122b1ca",
      "4c0abcc2aa874c5b8afa76cb564ccef6",
      "4406be15317f433d915dbbd11a2d147f",
      "44968fe34a63426cbb1471ad6df14bd6",
      "60a3ed7366c34af1ab961e47b4d73956",
      "e742bf3efe90476eb15931f617099c3f",
      "0998956ec1004cb78cfda7d611f3ff74",
      "390e33943de1453bbe200f00084b6997",
      "0cc9bf78ff1d41bf88f0d0b9226f861e",
      "cc4c81d3f6f3495fa8a47017b15076a0",
      "6a95691f3ad743ee9a9b1de461aa2536",
      "b9a12dacf9394d178887bc1d503705df",
      "0e175fc1bc89449f9d4dad05aee55bda",
      "d390e7b5ae5643cda1d45bee150c0148",
      "9873d93f65ef49ceb5656f8a34ea8a1c",
      "b7d51728411e47fd9526f9e4812ce6b1",
      "19c594bc84ac4386a077eaca41478ef2",
      "0d2185cf950d42ac892da7a7ffc64069",
      "e14d73bd04fb439da64a149562750038",
      "d5316d13a1304ec99b7d91a21065d72d",
      "513e502dc13241ea8ee9643998841018",
      "8d2269ebfd5a426eb43491ef3262839f",
      "eafbe75aaa834462b89d7d561714ec0d",
      "f53e012850b84648a9f40892ca94bcc2",
      "9c2360103ac6498691926402faf32628",
      "564372e13ae74891b58d8c76c603d793",
      "2d356426413e4647bdc9d6930d3cd97c",
      "0787e3e3cbff43f3a5193cac443ac3af",
      "0364087b43924de0bebe81e6e37a989f",
      "b09eb522c43b41a79a9fb4f756660521",
      "60b7809bd97f441db6d62f3cb81783b1",
      "ab06dad5341348d190160b33927cc758",
      "55f6c57a89784b68a4425f5d181b420f",
      "b229065e9e63477eb31ee27869264f8b",
      "2ee39cfd3cac43009b10f566c52d63d0",
      "be279ef76a524542bc9ff62f3c0363ed",
      "73929143bca44823916367e2c59ebc66",
      "8ccdf5cc2cbb4dc4b67baee1742b5940",
      "cbc192d684ac45b9852e68ed72537f1e",
      "2ba06281a7114c4c9aea0dd5d3d1bb52",
      "ba18aad992204b27a6f3d5bd10706c1d",
      "b3fd32b087774d86aa39fd23700c5ba9",
      "819eca5580414188959838c2c70adb76",
      "083a91019a9f46f8858e87bad78c51f9",
      "d63001a77eaf4dadb6bc46bc93e2940c",
      "2d51663ff28942e2a20ea992aefc03f2",
      "fa81b11306a7443b8da3291e6be179d0",
      "bf2b59f9334d4b0bb67714dda8dff291"
     ]
    },
    "id": "QP7SN9PLHMBD",
    "outputId": "3960d478-3b5a-4e77-e11b-602e079653bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4350a887573e4899a43bdb41409601a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/833 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1387bb34f3264a41be1ded94c813a43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9009a84d68714d6fa7181f7a717189b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a3ed7366c34af1ab961e47b4d73956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/416 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d51728411e47fd9526f9e4812ce6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/802 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d356426413e4647bdc9d6930d3cd97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccdf5cc2cbb4dc4b67baee1742b5940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MT5ForConditionalGeneration(\n",
       "  (shared): Embedding(250112, 512)\n",
       "  (encoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2iXIxFpHhRc"
   },
   "source": [
    "### Применение модели -- генерация реферата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lO_1nZEyHSvj"
   },
   "outputs": [],
   "source": [
    "def generate_summary(text, max_chars=MAX_CHARS):\n",
    "    text = clean_text(text)\n",
    "    inputs = tokenizer(text, max_length=1024, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "      summary_ids = model.generate(\n",
    "          **inputs,\n",
    "          max_length=150,\n",
    "          min_length=30,\n",
    "          num_beams=5,\n",
    "          repetition_penalty=2.0,\n",
    "          length_penalty=1.2,\n",
    "          no_repeat_ngram_size=3,\n",
    "          early_stopping=True\n",
    "      )\n",
    "\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary[:max_chars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHgUufj5HeU2"
   },
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlURnJlAHW3G",
    "outputId": "e6ffb1b2-14c5-426d-bf31-c8418b7021de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1:\n",
      "В Москве прошла выставка современных технологий. Посетители смогли увидеть роботов и дронов, дронов и новейшие разработки в сфере искусственного интеллекта.\n",
      "\n",
      "2:\n",
      "Учёные из Японии разработали метод восстановления изображений, которые видит человек, используя сигналы мозга. Эксперименты показали высокую точность восстановления фотографий, которая видит человека. По ученым, учёные создали метод восстановление изображений на мозга, пользуя сигналами мозга в резу\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Вчера в Москве прошла выставка современных технологий. Посетители смогли увидеть роботов, дронов и новейшие разработки в сфере искусственного интеллекта.\",\n",
    "    \"Учёные из Японии разработали метод восстановления изображений, которые видит человек, используя сигналы мозга. Эксперименты показали высокую точность восстановления.\"\n",
    "]\n",
    "\n",
    "for i, text in enumerate(texts, 1):\n",
    "    summary = generate_summary(text)\n",
    "    print(f\"\\n{i}:\\n{summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gjfiz2PKmtxY"
   },
   "source": [
    "### Оценка по метрикам ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "QT1R01BkHzyo"
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"В Москве прошла выставка современных технологий. Посетители смогли увидеть роботов, дронов и новейшие разработки в сфере искусственного интеллекта.\",\n",
    "    \"Учёные из Японии разработали метод восстановления изображений, которые видит человек, используя сигналы мозга. Эксперименты показали высокую точность восстановления.\",\n",
    "]\n",
    "\n",
    "reference_summaries = [\n",
    "    \"В Москве прошла выставка современных технологий с роботами и дронами.\",\n",
    "    \"Учёные из Японии восстановили изображения по сигналам мозга человека.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOX2E6mbnTZX",
    "outputId": "7f924a9a-db53-4416-eb80-061872bd59af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from rouge) (1.17.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "m_XmKJ4JH33l"
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def evaluate_summary(summary, reference):\n",
    "  for i, text in enumerate(reference):\n",
    "      rouge = Rouge()\n",
    "      scores = rouge.get_scores(summary[i], reference[i])[0]\n",
    "      print(f\"\\nТекст {i}:\\n{reference[i]}\\n{summary[i]}\")\n",
    "      for rouge_type in ['rouge-1', 'rouge-2', 'rouge-l']:\n",
    "        f_score = scores[rouge_type]['f']\n",
    "        print(f\"{rouge_type.upper()}: {f_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K96dvPYSujGS",
    "outputId": "0edecf07-7f58-4605-8106-f190c38969b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Текст 0:\n",
      "В Москве прошла выставка современных технологий с роботами и дронами.\n",
      "В Москве прошла выставка современных технологий. Посетители смогли увидеть роботов и дронов, дронов и новейшие разработки в сфере искусственного интеллекта.\n",
      "ROUGE-1: 0.4828\n",
      "ROUGE-2: 0.3571\n",
      "ROUGE-L: 0.4828\n",
      "\n",
      "Текст 1:\n",
      "Учёные из Японии восстановили изображения по сигналам мозга человека.\n",
      "Учёные из Японии разработали метод восстановления изображений, которые видит человек, используя сигналы мозга. Эксперименты показали высокую точность восстановления фотографий, которая видит человека. По ученым, учёные создали метод восстановление изображений на мозга, пользуя сигналами мозга в резу\n",
      "ROUGE-1: 0.2439\n",
      "ROUGE-2: 0.0930\n",
      "ROUGE-L: 0.2439\n"
     ]
    }
   ],
   "source": [
    "summary = [generate_summary(text) for text in texts]\n",
    "evaluate_summary(summary, reference_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKJykX3oncKR"
   },
   "source": [
    "## Обработка примеров JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Ji0eM23lpSS3"
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oz5c9I-RmJ_K",
    "outputId": "928bb234-9aca-418f-bc9a-4050ecd2eceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Увидеть мысль\n",
      "\n",
      "Японским ученым удалось распознать изображение , увиденное человеком , сканируя его мозг .\n",
      "\n",
      "Как пишет Yomiuri , группе сотрудников отделения нейроинформатики Международного исследовательского института передовых средств коммуникации ( Киото , Япония ) удалось восстановить изображение , увиденное человеком , опираясь только на сканирование электрических сигналов мозга .\n",
      "\n",
      "В ходе экспе\n"
     ]
    }
   ],
   "source": [
    "with open(\"example_texts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    example_texts = json.load(f)\n",
    "\n",
    "print(f\"{len(example_texts)}\")\n",
    "print(example_texts[0][:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmyqxVEomgNQ",
    "outputId": "d93771b3-7a7c-4a89-dc1a-0866f4f77c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1:\n",
      "«Увидеть мысль» Японским ученым удалось восстановить изображение, увиденное человеком, сканируя его мозг. В результате эксперимента исследователи продемонстрировали серию из 440 различных картинок, представлявших собой произвольное сочетание темных и светлых пятен на 100-пиксельном экране.\n",
      "\n",
      "2:\n",
      "Гидролизующий ацетилхолинэстеразное средство необратимого действия, акарицид широкого спектра действия. Применялся против комаров, клещей и клещей, паразитов, повреждающих фруктовые деревья, овощные деревья и декоративные растения.\n",
      "\n",
      "3:\n",
      "Власти Украины обещают сохранить двуязычие на востоке страны. На переговорах с главой МВД Арсением Яценюком и Ринатом Ахметовым в Донецке он предложил восстановить полномочия местных органов власти, которые будут избираться Областными советами.\n",
      "\n",
      "4:\n",
      "Московский мэр Москвы Борис Немцов заявил о том, что в прошлом году чиновники должны быть немедленно отправлен в отставку. По словам Михаила Лужкова, это может стать причиной того, что москвичи могут пойти на пенсию.\n",
      "\n",
      "5:\n",
      "В ходе заявления ходатайства в СИЗО, который пришел к уголовному делу о том, что его подозреваемый по уголовным делам может быть вынужден сделать его по образцу следственных постановлений из УПК.\n"
     ]
    }
   ],
   "source": [
    "generated_summaries = []\n",
    "\n",
    "for i, text in enumerate(example_texts):\n",
    "    summary = generate_summary(text)\n",
    "    generated_summaries.append(summary)\n",
    "    print(f\"\\n{i+1}:\\n{summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "JBJemK3_tdPh"
   },
   "outputs": [],
   "source": [
    "with open('generated_summaries.json', 'w', encoding='utf-8') as f:\n",
    "      json.dump(generated_summaries, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USRuGXnopXym",
    "outputId": "a3479f52-51ac-4103-df65-975bbf965206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Японские ученые смогли распознать изображение увиденное человеком сканируя его мозг. Восстановили изображение по сигналам мозговой активности. Показали картинки и измерили активность зрительной коры мозга.\n"
     ]
    }
   ],
   "source": [
    "with open(\"example_texts_summary.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    example_texts_summary = json.load(f)\n",
    "\n",
    "print(f\"{len(example_texts_summary)}\")\n",
    "print(example_texts_summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LgmMFifp8ck",
    "outputId": "b5a7d61c-c6c7-42cf-8af2-8652148b9238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Текст 0:\n",
      "Японские ученые смогли распознать изображение увиденное человеком сканируя его мозг. Восстановили изображение по сигналам мозговой активности. Показали картинки и измерили активность зрительной коры мозга.\n",
      "«Увидеть мысль» Японским ученым удалось восстановить изображение, увиденное человеком, сканируя его мозг. В результате эксперимента исследователи продемонстрировали серию из 440 различных картинок, представлявших собой произвольное сочетание темных и светлых пятен на 100-пиксельном экране.\n",
      "ROUGE-1: 0.1786\n",
      "ROUGE-2: 0.0727\n",
      "ROUGE-L: 0.1786\n",
      "\n",
      "Текст 1:\n",
      "Карбофос - фосфорорганический инсектицид широкого спектра. Вытеснен пиретроидами, но эффективен против клопов. Действует через инактивацию ацетилхолинэстеразы.\n",
      "Гидролизующий ацетилхолинэстеразное средство необратимого действия, акарицид широкого спектра действия. Применялся против комаров, клещей и клещей, паразитов, повреждающих фруктовые деревья, овощные деревья и декоративные растения.\n",
      "ROUGE-1: 0.1538\n",
      "ROUGE-2: 0.0526\n",
      "ROUGE-L: 0.1538\n",
      "\n",
      "Текст 2:\n",
      "Яценюк предложил децентрализацию власти на востоке Украины: ликвидацию областных администраций и передачу полномочий местным советам. Сохранен закон о региональных языках.\n",
      "Власти Украины обещают сохранить двуязычие на востоке страны. На переговорах с главой МВД Арсением Яценюком и Ринатом Ахметовым в Донецке он предложил восстановить полномочия местных органов власти, которые будут избираться Областными советами.\n",
      "ROUGE-1: 0.1538\n",
      "ROUGE-2: 0.0400\n",
      "ROUGE-L: 0.1154\n",
      "\n",
      "Текст 3:\n",
      "Доклад Немцова Лужков Итоги критикует мэра Москвы за коррупцию. Состояние жены Лужкова Батуриной миллиарды долларов. Лужков должен быть отправлен в отставку согласно докладу.\n",
      "Московский мэр Москвы Борис Немцов заявил о том, что в прошлом году чиновники должны быть немедленно отправлен в отставку. По словам Михаила Лужкова, это может стать причиной того, что москвичи могут пойти на пенсию.\n",
      "ROUGE-1: 0.1852\n",
      "ROUGE-2: 0.0727\n",
      "ROUGE-L: 0.1852\n",
      "\n",
      "Текст 4:\n",
      "Сатирический совет по написанию ходатайства по образцу УПК. После заголовка вводная я подозреваемый потом установил и ходатайствую. Следователя может хватить Кондратий.\n",
      "В ходе заявления ходатайства в СИЗО, который пришел к уголовному делу о том, что его подозреваемый по уголовным делам может быть вынужден сделать его по образцу следственных постановлений из УПК.\n",
      "ROUGE-1: 0.2500\n",
      "ROUGE-2: 0.0408\n",
      "ROUGE-L: 0.2500\n"
     ]
    }
   ],
   "source": [
    "evaluate_summary(generated_summaries, example_texts_summary)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}