{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Версия I"
      ],
      "metadata": {
        "id": "kY4YR8Ir3tJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Загрузка словаря"
      ],
      "metadata": {
        "id": "F77kavBZ3HzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://opencorpora.org/files/export/dict/dict.opcorpora.xml.zip\n",
        "! unzip dict.opcorpora.xml.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndiSLq_M3E_H",
        "outputId": "c225ad0a-ae6a-4c34-dc04-177b4e6fdd32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-24 11:51:27--  https://opencorpora.org/files/export/dict/dict.opcorpora.xml.zip\n",
            "Resolving opencorpora.org (opencorpora.org)... 172.67.163.210, 104.21.15.199, 2606:4700:3030::6815:fc7, ...\n",
            "Connecting to opencorpora.org (opencorpora.org)|172.67.163.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28757314 (27M) [application/zip]\n",
            "Saving to: ‘dict.opcorpora.xml.zip’\n",
            "\n",
            "dict.opcorpora.xml. 100%[===================>]  27.42M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-09-24 11:51:28 (195 MB/s) - ‘dict.opcorpora.xml.zip’ saved [28757314/28757314]\n",
            "\n",
            "Archive:  dict.opcorpora.xml.zip\n",
            "  inflating: dict.opcorpora.xml      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Считывание исходного словаря и создание словаря для лемматизатора"
      ],
      "metadata": {
        "id": "siecBeE53N32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lxml import etree\n",
        "\n",
        "def creat_dict():\n",
        "    dict_ = {}\n",
        "    lemmas = etree.iterparse('dict.opcorpora.xml', events=(\"end\",), tag=\"lemma\", recover=True)\n",
        "\n",
        "    for _ , lemma in lemmas:\n",
        "        l = lemma.find(\"l\")\n",
        "\n",
        "        lemma_text = l.attrib.get(\"t\")\n",
        "        g = l.findall(\"g\")\n",
        "        tag = g[0].attrib.get(\"v\", \"Unknown\")\n",
        "\n",
        "        for f in lemma.findall(\"f\"):\n",
        "            word = f.attrib.get(\"t\")\n",
        "            dict_[word] = [lemma_text, tag]\n",
        "\n",
        "        lemma.clear()\n",
        "    return dict_\n",
        "\n",
        "dict_ = creat_dict()"
      ],
      "metadata": {
        "id": "CePzPm0s3HR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Проверка работы словаря"
      ],
      "metadata": {
        "id": "wZhYnFjb5yrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dict_['стала'])"
      ],
      "metadata": {
        "id": "XpSjMjDo5yrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80d8ef0-9a8b-4ce6-f256-feb24be7fa39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['стал', 'VERB']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Считывание текста"
      ],
      "metadata": {
        "id": "LrZgMh3M52g0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyzXvRLP2tJl"
      },
      "outputs": [],
      "source": [
        "with open('text.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Преобразование текста к формату для обработки"
      ],
      "metadata": {
        "id": "KiZo37373ozp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNKczLMT3Gge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c29861-09b5-4ce0-f120-b5b4542a7683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Стала', 'стабильнее', 'экономическая', 'и', 'политическая', 'обстановка', 'предприятия', 'вывели', 'из', 'тени', 'зарплаты', 'сотрудников', 'Все', 'Гришины', 'одноклассники', 'уже', 'побывали', 'за', 'границей', 'он', 'был', 'чуть', 'ли', 'не', 'единственным', 'кого', 'не', 'вывозили', 'никуда', 'дальше', 'Красной', 'Пахры', 'Я', 'люблю', 'русскую', 'печь', 'и', 'печь', 'пироги']\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "def to_form(text):\n",
        "  clean_text = \"\".join(ch for ch in text if ch not in string.punctuation)\n",
        "  words = clean_text.strip().split()\n",
        "  print(words)\n",
        "\n",
        "  return words\n",
        "\n",
        "words = to_form(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Лемматизация"
      ],
      "metadata": {
        "id": "mHme0xs_3vs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for w in words:\n",
        "  if w.lower() not in dict_.keys():\n",
        "    result.append(f\"{w}{{Unknown}}\")\n",
        "  else:\n",
        "    lemma, tag = dict_[w.lower()]\n",
        "    result.append(f\"{w}{{{lemma}={tag}}}\")\n",
        "\n",
        "text_res = \" \".join(result)\n",
        "print(text_res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGOLJde6VzSf",
        "outputId": "91679e02-adff-493a-ec1a-a31ef6012ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Стала{стал=VERB} стабильнее{стабильнее=COMP} экономическая{экономический=ADJF} и{и=NOUN} политическая{политический=ADJF} обстановка{обстановка=NOUN} предприятия{предприятие=NOUN} вывели{вывел=VERB} из{иза=NOUN} тени{тень=NOUN} зарплаты{зарплата=NOUN} сотрудников{сотрудник=NOUN} Все{весь=ADJF} Гришины{гришин=ADJF} одноклассники{одноклассник=NOUN} уже{уже=PRCL} побывали{побывал=VERB} за{за=PREP} границей{граница=NOUN} он{он=NPRO} был{есть=VERB} чуть{чуть=CONJ} ли{ли=NOUN} не{не=PRCL} единственным{единственный=ADJF} кого{кто=NPRO} не{не=PRCL} вывозили{вывозил=VERB} никуда{никуда=ADVB} дальше{дальше=COMP} Красной{красный=ADJF} Пахры{пахра=NOUN} Я{я=NOUN} люблю{люблю=VERB} русскую{русский=ADJF} печь{печь=NOUN} и{и=NOUN} печь{печь=NOUN} пироги{пирога=NOUN}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Сохранение в файл"
      ],
      "metadata": {
        "id": "4nqNlY-W37Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text_res)\n"
      ],
      "metadata": {
        "id": "s-W6hG383-QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Версия II\n",
        "\n",
        "(Попытка решить проблему омонимов)"
      ],
      "metadata": {
        "id": "napOvVyL0LZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/UniversalDependencies/UD_Russian-SynTagRus/ -- Датасет для обучения модели с указанием частей речи"
      ],
      "metadata": {
        "id": "3kqh_bZq0VcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/UniversalDependencies/UD_Russian-SynTagRus/raw/refs/heads/master/ru_syntagrus-ud-train-a.conllu\n",
        "!wget https://github.com/UniversalDependencies/UD_Russian-SynTagRus/raw/refs/heads/master/ru_syntagrus-ud-train-b.conllu\n",
        "!wget https://github.com/UniversalDependencies/UD_Russian-SynTagRus/raw/refs/heads/master/ru_syntagrus-ud-train-c.conllu"
      ],
      "metadata": {
        "id": "kuhrNhWQ0p-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2998d3a-8cb1-4935-9d04-50ab6d6b16c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-07 13:38:29--  https://github.com/UniversalDependencies/UD_Russian-SynTagRus/raw/refs/heads/master/ru_syntagrus-ud-train-a.conllu\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/refs/heads/master/ru_syntagrus-ud-train-a.conllu [following]\n",
            "--2025-10-07 13:38:29--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/refs/heads/master/ru_syntagrus-ud-train-a.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41309373 (39M) [application/octet-stream]\n",
            "Saving to: ‘ru_syntagrus-ud-train-a.conllu’\n",
            "\n",
            "\r          ru_syntag   0%[                    ]       0  --.-KB/s               \rru_syntagrus-ud-tra 100%[===================>]  39.40M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-10-07 13:38:29 (503 MB/s) - ‘ru_syntagrus-ud-train-a.conllu’ saved [41309373/41309373]\n",
            "\n",
            "--2025-10-07 13:38:29--  https://github.com/UniversalDependencies/UD_Russian-SynTagRus/raw/refs/heads/master/ru_syntagrus-ud-train-b.conllu\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/refs/heads/master/ru_syntagrus-ud-train-b.conllu [following]\n",
            "--2025-10-07 13:38:29--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/refs/heads/master/ru_syntagrus-ud-train-b.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43413835 (41M) [text/plain]\n",
            "Saving to: ‘ru_syntagrus-ud-train-b.conllu’\n",
            "\n",
            "ru_syntagrus-ud-tra 100%[===================>]  41.40M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-10-07 13:38:29 (449 MB/s) - ‘ru_syntagrus-ud-train-b.conllu’ saved [43413835/43413835]\n",
            "\n",
            "--2025-10-07 13:38:29--  https://github.com/UniversalDependencies/UD_Russian-SynTagRus/raw/refs/heads/master/ru_syntagrus-ud-train-c.conllu\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/refs/heads/master/ru_syntagrus-ud-train-c.conllu [following]\n",
            "--2025-10-07 13:38:29--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/refs/heads/master/ru_syntagrus-ud-train-c.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33243340 (32M) [text/plain]\n",
            "Saving to: ‘ru_syntagrus-ud-train-c.conllu’\n",
            "\n",
            "ru_syntagrus-ud-tra 100%[===================>]  31.70M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-10-07 13:38:29 (408 MB/s) - ‘ru_syntagrus-ud-train-c.conllu’ saved [33243340/33243340]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_conllu_as_tagged_sentences(path, word_column=1, lemma_column = 2,upos_column=3):\n",
        "    sents = []\n",
        "    cur = []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                if cur:\n",
        "                    sents.append(cur)\n",
        "                    cur = []\n",
        "                continue\n",
        "            if line.startswith('#'):\n",
        "                continue\n",
        "            parts = line.split('\\t')\n",
        "            if '-' in parts[0] or '.' in parts[0]:\n",
        "                continue\n",
        "            word = parts[word_column]\n",
        "            lemma = parts[lemma_column]\n",
        "            upos = parts[upos_column]\n",
        "            cur.append((word, lemma,upos))\n",
        "    if cur:\n",
        "        sents.append(cur)\n",
        "    return sents"
      ],
      "metadata": {
        "id": "LCeTQ-LL0K2k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_1 = read_conllu_as_tagged_sentences('/content/ru_syntagrus-ud-train-a.conllu')\n",
        "train_2 = read_conllu_as_tagged_sentences('/content/ru_syntagrus-ud-train-b.conllu')\n",
        "train_3 = read_conllu_as_tagged_sentences('/content/ru_syntagrus-ud-train-c.conllu')\n",
        "train = []\n",
        "train.extend(train_1)\n",
        "train.extend(train_2)\n",
        "train.extend(train_3)"
      ],
      "metadata": {
        "id": "Tsy4jLYh07Cw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка модели **rubert-tiny2**"
      ],
      "metadata": {
        "id": "plVuLLNh1AUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "TOra0Z901EOd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "X = [[w for w, l, p in sent] for sent in train]\n",
        "y_pos = [[p for w, l, p in sent] for sent in train]\n",
        "y_lemma = [[l for w, l, p in sent] for sent in train]\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
        "unique_pos = sorted(list(set(p for sent in y_pos for p in sent)))\n",
        "unique_lemmas = sorted(list(set(l for sent in y_lemma for l in sent)))\n",
        "\n",
        "pos2id = {p: i for i, p in enumerate(unique_pos)}\n",
        "lemma2id = {l: i for i, l in enumerate(unique_lemmas)}\n",
        "\n",
        "\n",
        "def align_labels(words, labels, tokenizer, label2id):\n",
        "    tokenized = tokenizer(words, is_split_into_words=True)\n",
        "    word_ids = tokenized.word_ids()\n",
        "    aligned_labels = []\n",
        "    prev_word = None\n",
        "    for word_idx in word_ids:\n",
        "        if word_idx is None:\n",
        "            aligned_labels.append(-100)\n",
        "        elif word_idx != prev_word:\n",
        "            aligned_labels.append(label2id[labels[word_idx]])\n",
        "        else:\n",
        "            aligned_labels.append(-100)\n",
        "        prev_word = word_idx\n",
        "    return aligned_labels\n",
        "\n",
        "class PosLemmaDataset(Dataset):\n",
        "    def __init__(self, X, y_pos, y_lemma):\n",
        "        self.X = X\n",
        "        self.y_pos = y_pos\n",
        "        self.y_lemma = y_lemma\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y_pos[idx], self.y_lemma[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "        words_batch, pos_batch, lemma_batch = zip(*batch)\n",
        "        encoding = tokenizer(list(words_batch), is_split_into_words=True, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "        pos_labels = []\n",
        "        lemma_labels = []\n",
        "\n",
        "        for i, words in enumerate(words_batch):\n",
        "            pos_labels.append(torch.tensor(align_labels(words, pos_batch[i], tokenizer, pos2id)))\n",
        "            lemma_labels.append(torch.tensor(align_labels(words, lemma_batch[i], tokenizer, lemma2id)))\n",
        "\n",
        "        pos_labels = nn.utils.rnn.pad_sequence(pos_labels, batch_first=True, padding_value=-100)\n",
        "        lemma_labels = nn.utils.rnn.pad_sequence(lemma_labels, batch_first=True, padding_value=-100)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"],\n",
        "            \"attention_mask\": encoding[\"attention_mask\"],\n",
        "            \"pos_labels\": pos_labels,\n",
        "            \"lemma_labels\": lemma_labels\n",
        "        }\n",
        "\n",
        "dataset = PosLemmaDataset(X, y_pos, y_lemma)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "class JointPOSTaggerLemmaModel(nn.Module):\n",
        "    def __init__(self, base_model_name, num_pos_labels, num_lemma_labels):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(base_model_name)\n",
        "        hidden_size = self.bert.config.hidden_size\n",
        "        self.pos_classifier = nn.Linear(hidden_size, num_pos_labels)\n",
        "        self.lemma_classifier = nn.Linear(hidden_size, num_lemma_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, **kwargs):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden = outputs.last_hidden_state\n",
        "        pos_logits = self.pos_classifier(hidden)\n",
        "        lemma_logits = self.lemma_classifier(hidden)\n",
        "        return pos_logits, lemma_logits\n",
        "\n",
        "\n",
        "model = JointPOSTaggerLemmaModel(\"cointegrated/rubert-tiny2\",\n",
        "                                 num_pos_labels=len(pos2id),\n",
        "                                 num_lemma_labels=len(lemma2id)).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(dataloader):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        pos_labels = batch[\"pos_labels\"].to(device)\n",
        "        lemma_labels = batch[\"lemma_labels\"].to(device)\n",
        "\n",
        "        pos_logits, lemma_logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss_pos = loss_fn(pos_logits.view(-1, len(pos2id)), pos_labels.view(-1))\n",
        "        loss_lemma = loss_fn(lemma_logits.view(-1, len(lemma2id)), lemma_labels.view(-1))\n",
        "        loss = loss_pos + loss_lemma\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "id": "ZkQASwqj1GRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8541a0-8aef-431a-cbe2-24f01eac8ee7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "100%|██████████| 34816/34816 [13:55<00:00, 41.66it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 34816/34816 [13:30<00:00, 42.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | Loss: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 34816/34816 [13:31<00:00, 42.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | Loss: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8_wu66kb4Cpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(f'model_nlp.pt', f'/content/drive/MyDrive/model_nlp')"
      ],
      "metadata": {
        "id": "FmacHBwA3gFi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Предобработка текста"
      ],
      "metadata": {
        "id": "jzKJDVVq4Ivv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('text.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "aZr3AIdX2Lem"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def to_form(text):\n",
        "  clean_text = \"\".join(ch for ch in text if ch not in string.punctuation)\n",
        "  words = clean_text.strip().split()\n",
        "  print(words)\n",
        "\n",
        "  return words\n",
        "\n",
        "words = to_form(text)"
      ],
      "metadata": {
        "id": "eNlIyI5T2TJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f32bef-b365-495a-cba7-d85256ac5556"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Стала', 'стабильнее', 'экономическая', 'и', 'политическая', 'обстановка', 'предприятия', 'вывели', 'из', 'тени', 'зарплаты', 'сотрудников', 'Все', 'Гришины', 'одноклассники', 'уже', 'побывали', 'за', 'границей', 'он', 'был', 'чуть', 'ли', 'не', 'единственным', 'кого', 'не', 'вывозили', 'никуда', 'дальше', 'Красной', 'Пахры', 'Я', 'люблю', 'русскую', 'печь', 'и', 'печь', 'блины', 'Я', 'люблю', 'русскую', 'печь', 'Я', 'люблю', 'печь', 'пироги', 'Утром', 'я', 'ела', 'вкусные', 'суши', 'а', 'вечером', 'сушила', 'полотенце', 'от', 'слёз']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Применения модели"
      ],
      "metadata": {
        "id": "pXmMlRDU4L-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "encoding = tokenizer(words, is_split_into_words=True, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    pos_logits, lemma_logits = model(**encoding)\n",
        "pos_preds = pos_logits.argmax(-1).squeeze().tolist()\n",
        "lemma_preds = lemma_logits.argmax(-1).squeeze().tolist()\n",
        "\n",
        "\n",
        "word_ids = encoding.word_ids()\n",
        "used = set()\n",
        "print(\"\\nРезультат:\")\n",
        "for i, word_id in enumerate(word_ids):\n",
        "    if word_id is not None and word_id not in used:\n",
        "        used.add(word_id)\n",
        "        print(f\"{words[word_id]}{{{unique_lemmas[lemma_preds[i]]}={unique_pos[pos_preds[i]]}}}\")"
      ],
      "metadata": {
        "id": "G9UjP2_W152U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ca7bd8-accd-4a22-b93c-aaf6aa511a12"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Результат:\n",
            "Стала{стать=VERB}\n",
            "стабильнее{стабильный=ADJ}\n",
            "экономическая{экономический=ADJ}\n",
            "и{и=CCONJ}\n",
            "политическая{политический=ADJ}\n",
            "обстановка{обстановка=NOUN}\n",
            "предприятия{предприятие=NOUN}\n",
            "вывели{вывести=VERB}\n",
            "из{из=ADP}\n",
            "тени{тень=NOUN}\n",
            "зарплаты{зарплата=NOUN}\n",
            "сотрудников{сотрудник=NOUN}\n",
            "Все{весь=DET}\n",
            "Гришины{Григорий=PROPN}\n",
            "одноклассники{одноклассник=NOUN}\n",
            "уже{уже=ADV}\n",
            "побывали{побывать=VERB}\n",
            "за{за=ADP}\n",
            "границей{граница=NOUN}\n",
            "он{он=PRON}\n",
            "был{быть=AUX}\n",
            "чуть{чуть=ADV}\n",
            "ли{ли=PART}\n",
            "не{не=PART}\n",
            "единственным{единственный=ADJ}\n",
            "кого{кто=PRON}\n",
            "не{не=PART}\n",
            "вывозили{вывозить=VERB}\n",
            "никуда{никуда=ADV}\n",
            "дальше{далеко=ADV}\n",
            "Красной{красный=ADJ}\n",
            "Пахры{Паша=PROPN}\n",
            "Я{я=PRON}\n",
            "люблю{любить=VERB}\n",
            "русскую{русский=ADJ}\n",
            "печь{печь=NOUN}\n",
            "и{и=CCONJ}\n",
            "печь{печь=NOUN}\n",
            "блины{блин=NOUN}\n",
            "Я{я=PRON}\n",
            "люблю{любить=VERB}\n",
            "русскую{русский=ADJ}\n",
            "печь{печь=NOUN}\n",
            "Я{я=PRON}\n",
            "люблю{любить=VERB}\n",
            "печь{печь=NOUN}\n",
            "пироги{пирог=NOUN}\n",
            "Утром{утро=PROPN}\n",
            "я{я=PRON}\n",
            "ела{есть=VERB}\n",
            "вкусные{вкусный=ADJ}\n",
            "суши{суша=NOUN}\n",
            "а{а=CCONJ}\n",
            "вечером{вечер=NOUN}\n",
            "сушила{суша=VERB}\n",
            "полотенце{все=NOUN}\n",
            "от{от=ADP}\n",
            "слёз{сладкий=NOUN}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}